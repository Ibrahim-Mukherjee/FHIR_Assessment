{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORegh/UvC4CKcfOfRGksho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibrahim-Mukherjee/FHIR_Assessment/blob/main/FHIR_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2pZEP3iNAe8",
        "outputId": "5ec0ccbc-9cae-4173-a915-596f67554d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fhir-parser\n",
            "  Downloading FHIR_Parser-0.1.5-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from fhir-parser) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from fhir-parser) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->fhir-parser) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->fhir-parser) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->fhir-parser) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->fhir-parser) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->fhir-parser) (3.4)\n",
            "Installing collected packages: fhir-parser\n",
            "Successfully installed fhir-parser-0.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install fhir-parser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests"
      ],
      "metadata": {
        "id": "1h4PfYI0NRK-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/emisgroup/exa-data-eng-assessment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i39N2wxJNuE0",
        "outputId": "92994aa2-cca2-4d51-efea-a372fd0e6e61"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exa-data-eng-assessment'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 99 (delta 5), reused 3 (delta 3), pack-reused 90\u001b[K\n",
            "Unpacking objects: 100% (99/99), 8.04 MiB | 1.88 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all the JSON files in the data directory\n",
        "json_files = [f for f in os.listdir('/content/exa-data-eng-assessment/data') if f.endswith('.json')]\n",
        "\n",
        "# Create an empty list to store the DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop over the JSON files and convert them into DataFrames\n",
        "for json_file in json_files:\n",
        "    with open(f'/content/exa-data-eng-assessment/data/{json_file}', 'r') as f:\n",
        "        data = json.load(f)\n",
        "        df = pd.json_normalize(data)\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate the DataFrames into a single DataFrame\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "AGBOnA_-N2TF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J_BRBqGRMFb",
        "outputId": "d24d06ce-aa56-46b6-ea9a-58120c403e20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  resourceType         type                                              entry\n",
            "0       Bundle  transaction  [{'fullUrl': 'urn:uuid:7b3071eb-aacb-0596-d7b5...\n",
            "1       Bundle  transaction  [{'fullUrl': 'urn:uuid:b0478b4f-16f2-af38-d199...\n",
            "2       Bundle  transaction  [{'fullUrl': 'urn:uuid:6f1df156-8793-56a0-6df1...\n",
            "3       Bundle  transaction  [{'fullUrl': 'urn:uuid:9ce2b3c9-0f19-e01b-d789...\n",
            "4       Bundle  transaction  [{'fullUrl': 'urn:uuid:718f37a0-cb8f-fb74-03d3...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmaRxSDfRcFb",
        "outputId": "28df0e42-af9a-40e4-d213-878e629a6a2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resourceType                                               Bundle\n",
            "type                                                  transaction\n",
            "entry           [{'fullUrl': 'urn:uuid:7b3071eb-aacb-0596-d7b5...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# List all the JSON files in the data directory\n",
        "json_files = [f for f in os.listdir('/content/exa-data-eng-assessment/data') if f.endswith('.json')]\n",
        "\n",
        "# Create an empty list to store the DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop over the JSON files and convert them into DataFrames\n",
        "for json_file in json_files:\n",
        "    with open(f'/content/exa-data-eng-assessment/data/{json_file}', 'r') as f:\n",
        "        data = json.load(f)\n",
        "        df = pd.json_normalize(data)\n",
        "        patient_id = data['entry'][0]['resource']['id']\n",
        "        df['patient_id'] = patient_id\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate the DataFrames into a single DataFrame\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "-pXpRq6_StwL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "zsc40gAbUMAc"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}